# Type_Safe Performance Optimization - LLM Usage Brief

**Version**: v3.65.0  
**Status**: Problem analyzed, solution designed  
**Purpose**: Document the performance problem, analysis, and optimization strategy for Type_Safe object creation  
**Related**: `type_safe_config__llm_usage_brief__v1.0.md` (implementation details)  
**Repo**: https://github.com/owasp-sbot/OSBot-Utils

---

## The Problem

### Type_Safe Object Creation is Too Slow

Type_Safe provides excellent runtime safety and developer experience, but the cost is significant:

```
Plain Python class:     ~300-500 ns per object
Type_Safe class:        ~10,000-15,000 ns per object (20-40x slower)
```

For single objects, this is invisible. For bulk operations, it's crippling:

```python
# Creating 1,000 nodes for a graph
nodes = [Schema__Node(**d) for d in data]     # 10-15 SECONDS with Type_Safe
                                               # vs ~0.5ms with plain Python
```

### Real-World Impact: MGraph

The MGraph library uses Type_Safe throughout. A typical graph index:

```python
class MGraph__Index(Type_Safe):
    nodes_by_id    : Index__Nodes__By_Id
    nodes_by_type  : Index__Nodes__By_Type
    edges_by_id    : Index__Edges__By_Id
    edges_by_type  : Index__Edges__By_Type
    edges_from     : Index__Edges__From
    edges_to       : Index__Edges__To
```

Each index contains nested Type_Safe objects:

```python
class Index__Nodes__By_Id(Type_Safe):
    data: Schema__Index__Data                  # Another Type_Safe

class Schema__Index__Data(Type_Safe):
    index   : Dict[Safe_Id, Safe_Id]           # Type_Safe__Dict
    reverse : Dict[Safe_Id, List[Safe_Id]]     # Type_Safe__Dict
```

**Result**: Creating an empty `MGraph__Index` takes **~1,800 μs** (1.8ms) because it recursively creates ~20 nested Type_Safe objects.

For `Html_MGraph` with 6 indexes: **~10ms just for initialization**.

### Target Performance

| Object Type | Current | Target | Improvement |
|-------------|---------|--------|-------------|
| Simple Type_Safe | ~12,000 ns | <1,000 ns | 12x |
| MGraph__Index | ~1,800 μs | <200 μs | 9x |
| Html_MGraph init | ~10 ms | <1 ms | 10x |
| 1,000 node graph load | ~15 s | <100 ms | 150x |

---

## Analysis: Where Does the Time Go?

### Baseline Measurements

Using `osbot_utils.testing.performance.Performance_Measure__Session`:

```python
class Schema__Simple(Type_Safe):
    name  : str
    value : int

# Measured: ~12,000 ns per object
```

### Type_Safe.__init__ Breakdown

| Step | Operation | Cost | Notes |
|------|-----------|------|-------|
| 1 | MRO walk | ~2-3 μs | `__cls_kwargs__()` walks inheritance |
| 2 | Default creation | ~1-5 μs | Creates nested Type_Safe, collections |
| 3 | Type conversion | ~1-2 μs | str → Safe_Id, etc. |
| 4 | Validation | ~1-2 μs | isinstance checks |
| 5 | __setattr__ | ~2-3 μs | Per-attribute validation |
| **Total** | | **~10-15 μs** | Simple object |

For nested objects, steps 2-5 cascade recursively.

### The Cascade Problem

```
MGraph__Index.__init__                         # 12 μs
  ├─ Index__Nodes__By_Id.__init__              # 12 μs
  │    └─ Schema__Index__Data.__init__         # 12 μs
  │         ├─ Type_Safe__Dict.__init__        # 5 μs
  │         └─ Type_Safe__Dict.__init__        # 5 μs
  ├─ Index__Nodes__By_Type.__init__            # ... same pattern
  ├─ Index__Edges__By_Id.__init__              # ... same pattern
  └─ ... (6 indexes total)
                                               ─────────
                                               ~1,800 μs total
```

Each Type_Safe creation does full validation, even for trusted internal objects.

---

## Solution Strategy

### Key Insight: Context-Aware Behavior

Most Type_Safe overhead is **validation** - checking types, converting values, verifying constraints. This is valuable for:
- User-provided data (API inputs, config files)
- Development/debugging
- Data boundaries (external → internal)

But it's wasteful for:
- Internal object construction
- Bulk loading from trusted sources (databases, serialized data)
- Performance-critical paths

**Solution**: Make validation **context-dependent** via stack-based configuration.

### The Stack Variable Discovery Pattern

Instead of per-object flags or global state, use a configuration object discoverable via stack walk:

```python
_type_safe_config_ = Type_Safe__Config(skip_validation=True)
with _type_safe_config_:
    # All Type_Safe objects created here detect the config
    # and skip expensive validation steps
    graph = MGraph__Index()                    # ~200 μs instead of ~1,800 μs
```

**Benefits:**
- No instance attribute pollution
- No global state
- Automatic propagation to nested objects
- Self-cleaning (config gone when scope exits)
- Composable (combine multiple optimizations)

See `type_safe_config__llm_usage_brief__v1.0.md` for implementation details.

### Incremental Optimization

Rather than one "fast mode", provide granular control over each __init__ step:

```python
# Level 1: Just skip setattr validation
_type_safe_config_ = Type_Safe__Config(skip_setattr=True)

# Level 2: Also skip type conversion
_type_safe_config_ = Type_Safe__Config(skip_setattr=True, skip_conversion=True)

# Level 3: Also skip default creation (caller provides all)
_type_safe_config_ = Type_Safe__Config(skip_setattr=True, skip_conversion=True, skip_defaults=True)

# Level 4: Also use cached MRO (maximum speed)
_type_safe_config_ = Type_Safe__Config(skip_setattr=True, skip_conversion=True, skip_defaults=True, skip_mro_walk=True)
```

This allows:
- Profile each step independently
- Choose the right level for each use case
- Maintain some safety while gaining speed

---

## Use Cases

### Use Case 1: Graph Loading from Database

```python
def load_graph_from_db(graph_id: str) -> MGraph:
    rows = db.query("SELECT * FROM nodes WHERE graph_id = ?", graph_id)
    
    # Data comes from trusted source (our own database)
    # No need for validation - just hydrate fast
    _type_safe_config_ = Type_Safe__Config(skip_validation = True ,
                                           skip_conversion = True )
    with _type_safe_config_:
        nodes = [Schema__Node(**row) for row in rows]
    
    return MGraph(nodes=nodes)
```

**Before**: 15 seconds for 1,000 nodes  
**After**: ~100ms for 1,000 nodes

### Use Case 2: JSON Deserialization

```python
def from_json(json_data: dict) -> MGraph:
    # JSON data structure is known/trusted
    _type_safe_config_ = Type_Safe__Config(skip_validation=True)
    with _type_safe_config_:
        return MGraph.from_json(json_data)
```

### Use Case 3: Index Initialization

```python
class MGraph:
    def __init__(self):
        # Indexes are internal structure - no external data
        _type_safe_config_ = Type_Safe__Config(skip_validation  = True ,
                                               on_demand_nested = True )
        with _type_safe_config_:
            self.index = MGraph__Index()       # ~90 μs instead of ~1,800 μs
```

### Use Case 4: Batch Processing Pipeline

```python
def process_documents(docs: List[dict]) -> List[Schema__Document]:
    # First pass: fast creation
    _type_safe_config_ = Type_Safe__Config(skip_validation=True)
    with _type_safe_config_:
        objects = [Schema__Document(**d) for d in docs]
    
    # Second pass: validate (optional, can be done lazily)
    for obj in objects:
        obj.__validate__()                     # Explicit validation if needed
    
    return objects
```

### Use Case 5: Testing with Real Data

```python
def test__large_graph_operations(self):
    # Load test fixture fast
    _type_safe_config_ = Type_Safe__Config(skip_validation=True)
    with _type_safe_config_:
        graph = MGraph.from_json(LARGE_TEST_FIXTURE)
    
    # Now test operations (normal validation in effect)
    graph.add_node(Schema__Node(id="new"))     # Validated normally
```

---

## Alternative Approaches Considered

### 1. Subclass Override (Type_Safe__Fast_Mode)

```python
class Type_Safe__Fast_Mode(Type_Safe):
    def __init__(self, **kwargs):
        # Bypass validation
        for k, v in kwargs.items():
            object.__setattr__(self, k, v)
```

**Problems:**
- Requires changing inheritance of all classes
- Doesn't help with nested objects (they're still Type_Safe)
- All-or-nothing (can't mix validated and fast)

### 2. Thread-Local Flag

```python
_fast_mode = threading.local()
_fast_mode.enabled = True
```

**Problems:**
- Global state that can leak
- Requires explicit cleanup
- Exception-safety concerns

### 3. Parameter Passing

```python
def __init__(self, _skip_validation=False, **kwargs):
    ...
```

**Problems:**
- Pollutes every constructor signature
- Doesn't propagate to nested objects automatically
- Breaks existing code

### 4. Class Decorator

```python
@fast_mode
class Schema__Node(Type_Safe):
    ...
```

**Problems:**
- Static (can't enable/disable at runtime)
- All instances affected, no context control

### Why Stack Variable Discovery Wins

| Approach | Propagates | No Global State | Runtime Control | Backward Compatible |
|----------|------------|-----------------|-----------------|---------------------|
| Subclass | ✗ | ✓ | ✗ | ✗ |
| Thread-local | ✓ | ✗ | ✓ | ✓ |
| Parameter | ✗ | ✓ | ✓ | ✗ |
| Decorator | ✗ | ✓ | ✗ | ✓ |
| **Stack Discovery** | **✓** | **✓** | **✓** | **✓** |

---

## On-Demand Creation

### The Insight

For complex indexes like `MGraph__Index`, most nested objects are **never accessed**:

```python
index = MGraph__Index()
# Only uses nodes_by_id - why create all 6 indexes?
node = index.nodes_by_id.get(some_id)
```

### Solution: Create on First Access

```python
_type_safe_config_ = Type_Safe__Config(on_demand_nested=True)
with _type_safe_config_:
    index = MGraph__Index()                    # Creates NOTHING yet
    
# Later...
node = index.nodes_by_id.get(id)               # NOW creates nodes_by_id
```

**Impact:**
- MGraph__Index: 1,800 μs → ~90 μs (20x faster)
- Only pays for what you use
- Combined with skip_validation for maximum speed

See `Type_Safe__On_Demand` in uploads for the prototype that validates this approach.

---

## Preservation of Type_Safe Semantics

### What MUST Be Preserved

Even in "fast mode", Type_Safe objects must:

1. **Have correct structure** - all annotated attributes exist
2. **Support serialization** - `.json()` works
3. **Support comparison** - `__eq__` works
4. **Be inspectable** - `__cls_kwargs__()` returns correct info
5. **Allow normal operations after creation** - validation on subsequent `setattr`

### What CAN Be Skipped (During Creation)

1. **Type validation** - isinstance checks
2. **Type conversion** - str → Safe_Id coercion
3. **Default creation** - if caller provides all values
4. **MRO walking** - if class-level cache exists
5. **__setattr__ hooks** - use object.__setattr__

### The Contract

```python
_type_safe_config_ = Type_Safe__Config(skip_validation=True)
with _type_safe_config_:
    obj = Schema__Node(id="abc", value=123)

# Object is now normal Type_Safe
obj.id = "xyz"                                 # Validated! (outside fast context)
obj.json()                                     # Works
obj == other                                   # Works
```

---

## Expected Performance Results

### Per-Object Creation

| Configuration | Time | vs Baseline |
|---------------|------|-------------|
| Baseline (no config) | ~12,000 ns | 1x |
| skip_setattr only | ~8,000 ns | 1.5x |
| + skip_validation | ~6,000 ns | 2x |
| + skip_conversion | ~4,000 ns | 3x |
| + skip_defaults | ~2,000 ns | 6x |
| + skip_mro_walk (cached) | ~1,000 ns | **12x** |
| + on_demand_nested | ~500 ns | **24x** |

### MGraph__Index

| Configuration | Time | vs Baseline |
|---------------|------|-------------|
| Baseline | ~1,800 μs | 1x |
| skip_validation | ~400 μs | 4.5x |
| + on_demand_nested | ~90 μs | **20x** |

### Html_MGraph (6 indexes)

| Configuration | Time | vs Baseline |
|---------------|------|-------------|
| Baseline | ~10 ms | 1x |
| With optimization | <1 ms | **10x** |

---

## Implementation Roadmap

### Phase 1: Infrastructure ✓
- [x] Design stack variable discovery pattern
- [x] Design frame injection caching
- [x] Design Type_Safe__Config class
- [x] Document in LLM briefs

### Phase 2: Core Implementation
- [ ] Implement `find_type_safe_config()`
- [ ] Add config check to `Type_Safe.__init__`
- [ ] Verify backward compatibility

### Phase 3: Incremental Flags
- [ ] Implement & benchmark `skip_setattr`
- [ ] Implement & benchmark `skip_validation`
- [ ] Implement & benchmark `skip_conversion`
- [ ] Implement & benchmark `skip_defaults`
- [ ] Implement & benchmark `skip_mro_walk`

### Phase 4: On-Demand
- [ ] Implement `on_demand_nested`
- [ ] Migrate from `Type_Safe__On_Demand` class

### Phase 5: Validation
- [ ] Benchmark against targets
- [ ] Test with MGraph use cases
- [ ] Test with Html_MGraph

---

## Key Takeaways

1. **Type_Safe is 20-40x slower than plain Python** - acceptable for most uses, problematic for bulk operations

2. **The cost is validation, not structure** - we can skip validation while preserving Type_Safe semantics

3. **Stack-based configuration is the cleanest solution** - no global state, automatic propagation, self-cleaning

4. **Incremental optimization allows profiling** - disable one step at a time, measure impact

5. **On-demand creation multiplies the gains** - don't create what you don't use

6. **Target: 10-20x improvement** - from ~12,000 ns to ~500-1,000 ns per object

---

## References

- `type_safe_config__llm_usage_brief__v1.0.md` - Configuration implementation details
- `stack_variable_discovery__llm_usage_brief__v1.0.md` - Generic stack discovery pattern
- `Type_Safe__On_Demand.py` - Prototype for on-demand creation
- `osbot_utils.testing.performance.Performance_Measure__Session` - Benchmarking tool
