# Type_Safe Performance Schemas: Implementation Briefing

**Version:** Based on OSBot-Utils v3.69.1  
**Purpose:** Guide for implementing type-safe performance benchmark schemas  
**Context:** This document provides the patterns and primitives used in the OSBot-Utils performance measurement infrastructure.

---

## Part 1: Core Type_Safe Principles

### 1.1 What is Type_Safe?

Type_Safe is a **runtime type checking framework** for Python that enforces type constraints during execution. Unlike Python's type hints (which are ignored at runtime), Type_Safe validates every operation, auto-initializes attributes, and provides domain-specific primitive types.

**Key differences from standard Python:**

| Feature | Python Type Hints | Type_Safe |
|---------|------------------|-----------|
| Runtime enforcement | ❌ Ignored | ✓ Every operation |
| Auto-initialization | ❌ Manual | ✓ Automatic |
| Validation | ❌ None | ✓ On assignment |
| Domain primitives | ❌ None | ✓ 100+ specialized types |

### 1.2 Critical Rule: Ban Raw Primitives

**NEVER use raw `str`, `int`, or `float` in Type_Safe classes.** 

```python
# ✗ WRONG - Raw primitives are dangerous
class Schema__Perf_Report__Metadata(Type_Safe):
    date         : str                           # Can contain anything
    version      : str                           # No validation
    measure_mode : str                           # Should be enum
    description  : str                           # No length limits

# ✓ CORRECT - Domain-specific types
class Schema__Perf_Report__Metadata(Type_Safe):
    date         : Timestamp_Now                 # Auto-generates, validated
    version      : Safe_Str__Version             # Format: v{major}.{minor}.{patch}
    measure_mode : Enum__Measure_Mode            # QUICK, FAST, DEFAULT
    description  : Safe_Str__Benchmark__Description  # Length-limited, sanitized
```

**Why this matters:**
- **String**: SQL injection, XSS, buffer overflows, command injection
- **Integer**: Overflow bugs, negative values where positive expected
- **Float**: Financial calculation errors, precision loss

### 1.3 Schema Classes Must Be Pure Data Containers

**CRITICAL: Schema classes should ONLY contain type annotations - NO methods, NO business logic!**

```python
# ✗ WRONG - Methods in schema
class Schema__Perf_Report__Analysis(Type_Safe):
    bottleneck_id  : Safe_Str__Benchmark_Id
    bottleneck_pct : Safe_Float__Percentage_Change
    
    def calculate_impact(self) -> float:        # NO! Move to helper class
        return self.bottleneck_pct * 100

# ✓ CORRECT - Schema is pure data
class Schema__Perf_Report__Analysis(Type_Safe):
    bottleneck_id  : Safe_Str__Benchmark_Id
    bottleneck_pct : Safe_Float__Percentage_Change
    key_insight    : Safe_Str__Benchmark__Description
    overhead_ns    : Safe_UInt
```

---

## Part 2: Available Primitives for Performance Schemas

### 2.1 Core Numeric Primitives

| Type | Description | Default | Import |
|------|-------------|---------|--------|
| `Safe_Int` | Signed integer with validation | `0` | `osbot_utils.type_safe.primitives.core.Safe_Int` |
| `Safe_UInt` | Unsigned integer (≥0) | `0` | `osbot_utils.type_safe.primitives.core.Safe_UInt` |
| `Safe_Float` | Float with precision control | `0.0` | `osbot_utils.type_safe.primitives.core.Safe_Float` |

**For performance timing values, always use `Safe_UInt`** (nanoseconds are never negative):

```python
class Schema__Perf_Report__Benchmark(Type_Safe):
    time_ns      : Safe_UInt                     # Nanosecond timing
    total_ns     : Safe_UInt                     # Aggregate timing
    sample_count : Safe_UInt                     # Number of samples
```

### 2.2 Percentage and Float Primitives

| Type | Description | Range | Precision |
|------|-------------|-------|-----------|
| `Safe_Float__Percentage_Change` | Percentage change values | Any | Float |
| `Safe_Float__Percentage_Exact` | Exact percentage | 0.0-100.0 | 2 decimals |
| `Safe_UInt__Percentage` | Integer percentage | 0-100 | Integer |

```python
from osbot_utils.type_safe.primitives.domains.numerical.safe_float.Safe_Float__Percentage_Change import Safe_Float__Percentage_Change

class Schema__Perf_Report__Benchmark(Type_Safe):
    pct_of_total : Safe_Float__Percentage_Change  # Can be negative for improvements
```

### 2.3 String Primitives Used in Performance Code

The performance infrastructure uses several specialized string types:

| Type | Max Length | Purpose | Characters Allowed |
|------|------------|---------|-------------------|
| `Safe_Str__Benchmark_Id` | 100 | Full benchmark identifier | `A_01__python__nop` |
| `Safe_Str__Benchmark__Section` | 50 | Section identifier | `A`, `B`, `Python` |
| `Safe_Str__Benchmark__Index` | 10 | Index within section | `01`, `02` |
| `Safe_Str__Benchmark__Title` | 200 | Session/benchmark title | Alphanumeric + spaces |
| `Safe_Str__Benchmark__Description` | 4096 | Rich descriptions | Wide character set |
| `Safe_Str__Benchmark__Report` | 1MB | Full report text | Text + table chars |
| `Safe_Str__Version` | varies | Version strings | `v1.0.0` format |

**Import paths:**
```python
from osbot_utils.helpers.performance.benchmark.schemas.safe_str.Safe_Str__Benchmark_Id           import Safe_Str__Benchmark_Id
from osbot_utils.helpers.performance.benchmark.schemas.safe_str.Safe_Str__Benchmark__Section     import Safe_Str__Benchmark__Section
from osbot_utils.helpers.performance.benchmark.schemas.safe_str.Safe_Str__Benchmark__Index       import Safe_Str__Benchmark__Index
from osbot_utils.helpers.performance.benchmark.schemas.safe_str.Safe_Str__Benchmark__Title       import Safe_Str__Benchmark__Title
from osbot_utils.helpers.performance.benchmark.schemas.safe_str.Safe_Str__Benchmark__Description import Safe_Str__Benchmark__Description
```

### 2.4 Identifier and Timestamp Primitives

| Type | Description | Auto-generates |
|------|-------------|----------------|
| `Timestamp_Now` | Current timestamp in milliseconds | ✓ Yes |
| `Safe_Id` | General safe identifier (512 chars) | No |
| `Random_Guid` | Random UUID4 | ✓ Yes |

```python
from osbot_utils.type_safe.primitives.domains.identifiers.safe_int.Timestamp_Now import Timestamp_Now

class Schema__Perf__Benchmark__Session(Type_Safe):
    timestamp : Timestamp_Now                    # Auto-generates current time on creation
```

### 2.5 File Path Primitives

| Type | Max Length | Purpose |
|------|------------|---------|
| `Safe_Str__File__Path` | 1024 | File system paths |
| `Safe_Str__File__Name` | varies | Filenames only |

```python
from osbot_utils.type_safe.primitives.domains.files.safe_str.Safe_Str__File__Path import Safe_Str__File__Path

class Schema__Perf_Benchmark__Timing__Config(Type_Safe):
    output_path   : Safe_Str__File__Path         # /path/to/output
    output_prefix : Safe_Str__File__Name         # benchmark
```

---

## Part 3: Enum Types for Performance Schemas

### 3.1 Available Enums

The performance infrastructure defines several enums:

```python
# Measurement accuracy vs speed tradeoff
class Enum__Measure_Mode(Enum):
    QUICK   = 'quick'                           # ~100 iterations, fastest
    FAST    = 'fast'                            # ~1,000 iterations, balanced
    DEFAULT = 'default'                         # ~10,000 iterations, most accurate

# Performance trend indicators
class Enum__Benchmark__Trend(Enum):
    STRONG_IMPROVEMENT = 'strong_improvement'   # > 10% faster
    IMPROVEMENT        = 'improvement'          # 0-10% faster
    UNCHANGED          = 'unchanged'            # No change
    REGRESSION         = 'regression'           # 0-10% slower
    STRONG_REGRESSION  = 'strong_regression'    # > 10% slower

# Comparison operation status
class Enum__Comparison__Status(Enum):
    SUCCESS                     = 'success'
    ERROR_NO_SESSIONS           = 'no_sessions'
    ERROR_INSUFFICIENT_SESSIONS = 'insufficient_sessions'
    ERROR_NO_COMMON_BENCHMARKS  = 'no_common_benchmarks'

# Hypothesis test outcome
class Enum__Hypothesis__Status(Enum):
    SUCCESS      = 'success'                    # Met or exceeded target
    FAILURE      = 'failure'                    # Did not meet target
    INCONCLUSIVE = 'inconclusive'               # Mixed results
    REGRESSION   = 'regression'                 # Performance got worse

# Time display units
class Enum__Time_Unit(Enum):
    NANOSECONDS  = 'ns'                         # Default
    MICROSECONDS = 'µs'
    MILLISECONDS = 'ms'
    SECONDS      = 's'
```

**Import paths:**
```python
from osbot_utils.helpers.performance.benchmark.schemas.enums.Enum__Measure_Mode      import Enum__Measure_Mode
from osbot_utils.helpers.performance.benchmark.schemas.enums.Enum__Benchmark__Trend  import Enum__Benchmark__Trend
from osbot_utils.helpers.performance.benchmark.schemas.enums.Enum__Comparison__Status import Enum__Comparison__Status
from osbot_utils.helpers.performance.benchmark.schemas.enums.Enum__Time_Unit         import Enum__Time_Unit
```

---

## Part 4: Type-Safe Collections

### 4.1 Why Subclass Collections?

Instead of using `List[str]` or `Dict[str, int]`, the performance code creates **named collection subclasses**:

```python
# ✗ AVOID: Generic annotations
class Schema__Report(Type_Safe):
    scores     : List[int]                      # What kind of scores?
    benchmarks : Dict[str, Schema__Benchmark]   # Keys are what?

# ✓ PREFERRED: Named collection subclasses
class List__Scores(Type_Safe__List):
    expected_type = Safe_UInt

class Dict__Benchmark_Results(Type_Safe__Dict):
    expected_key_type   = Safe_Str__Benchmark_Id
    expected_value_type = Schema__Perf__Benchmark__Result

class Schema__Report(Type_Safe):
    scores     : List__Scores                   # Self-documenting
    benchmarks : Dict__Benchmark_Results        # Clear purpose
```

### 4.2 Naming Convention

Use prefix pattern: `{CollectionType}__{Domain}__{Description}`

| Pattern | Example |
|---------|---------|
| `Dict__*` | `Dict__Benchmark_Results`, `Dict__Benchmark__Legend` |
| `List__*` | `List__Scores`, `List__Titles`, `List__Benchmark_Comparisons` |
| `Set__*` | `Set__Permission__Ids` |

### 4.3 Collection Subclasses in Performance Code

**Dict subclasses:**
```python
class Dict__Benchmark_Results(Type_Safe__Dict):
    expected_key_type   = Safe_Str__Benchmark_Id
    expected_value_type = Schema__Perf__Benchmark__Result

class Dict__Benchmark_Sessions(Type_Safe__Dict):
    expected_key_type   = Safe_Str__Benchmark_Id
    expected_value_type = Performance_Measure__Session

class Dict__Benchmark__Legend(Type_Safe__Dict):
    expected_key_type   = Safe_Str__Benchmark__Section
    expected_value_type = Safe_Str__Benchmark__Title
```

**List subclasses:**
```python
class List__Benchmark_Sessions(Type_Safe__List):
    expected_type = Schema__Perf__Benchmark__Session

class List__Benchmark_Comparisons(Type_Safe__List):
    expected_type = Schema__Perf__Benchmark__Comparison

class List__Benchmark_Evolutions(Type_Safe__List):
    expected_type = Schema__Perf__Benchmark__Evolution

class List__Scores(Type_Safe__List):
    expected_type = Safe_UInt

class List__Titles(Type_Safe__List):
    expected_type = Safe_Str__Benchmark__Title
```

**Import paths:**
```python
from osbot_utils.type_safe.type_safe_core.collections.Type_Safe__Dict import Type_Safe__Dict
from osbot_utils.type_safe.type_safe_core.collections.Type_Safe__List import Type_Safe__List
```

---

## Part 5: Migration Examples

### 5.1 Schema__Perf_Report__Metadata

**Before (raw primitives):**
```python
class Schema__Perf_Report__Metadata(Type_Safe):
    date         : str
    version      : str
    test_input   : str
    measure_mode : str
    description  : str
```

**After (type-safe):**
```python
from osbot_utils.type_safe.Type_Safe                                                             import Type_Safe
from osbot_utils.type_safe.primitives.domains.identifiers.safe_int.Timestamp_Now                 import Timestamp_Now
from osbot_utils.type_safe.primitives.domains.common.safe_str.Safe_Str__Version                  import Safe_Str__Version
from osbot_utils.helpers.performance.benchmark.schemas.enums.Enum__Measure_Mode                  import Enum__Measure_Mode
from osbot_utils.helpers.performance.benchmark.schemas.safe_str.Safe_Str__Benchmark__Description import Safe_Str__Benchmark__Description

class Schema__Perf_Report__Metadata(Type_Safe):
    timestamp    : Timestamp_Now                              # Auto-generates current time
    version      : Safe_Str__Version                          # Format: v{major}.{minor}.{patch}
    test_input   : Safe_Str__Benchmark__Description           # Sanitized, max 4096 chars
    measure_mode : Enum__Measure_Mode                         # QUICK, FAST, DEFAULT
    description  : Safe_Str__Benchmark__Description           # Sanitized description
```

### 5.2 Schema__Perf_Report__Benchmark

**Before (raw primitives):**
```python
class Schema__Perf_Report__Benchmark(Type_Safe):
    benchmark_id : str
    time_ns      : int
    category     : str
    pct_of_total : float
```

**After (type-safe):**
```python
from osbot_utils.type_safe.Type_Safe                                                                     import Type_Safe
from osbot_utils.type_safe.primitives.core.Safe_UInt                                                     import Safe_UInt
from osbot_utils.helpers.performance.benchmark.schemas.safe_str.Safe_Str__Benchmark_Id                   import Safe_Str__Benchmark_Id
from osbot_utils.helpers.performance.benchmark.schemas.safe_str.Safe_Str__Benchmark__Section             import Safe_Str__Benchmark__Section
from osbot_utils.type_safe.primitives.domains.numerical.safe_float.Safe_Float__Percentage_Change         import Safe_Float__Percentage_Change

class Schema__Perf_Report__Benchmark(Type_Safe):
    benchmark_id : Safe_Str__Benchmark_Id                     # Max 100 chars, validated format
    time_ns      : Safe_UInt                                  # Unsigned, never negative
    category     : Safe_Str__Benchmark__Section               # Max 50 chars, clean chars
    pct_of_total : Safe_Float__Percentage_Change              # Percentage with sign
```

### 5.3 Schema__Perf_Report__Category

**Before (raw primitives):**
```python
class Schema__Perf_Report__Category(Type_Safe):
    name         : str
    total_ns     : int
    pct_of_total : float
    benchmarks   : List[str]
```

**After (type-safe):**
```python
from osbot_utils.type_safe.Type_Safe                                                                     import Type_Safe
from osbot_utils.type_safe.primitives.core.Safe_UInt                                                     import Safe_UInt
from osbot_utils.type_safe.type_safe_core.collections.Type_Safe__List                                    import Type_Safe__List
from osbot_utils.helpers.performance.benchmark.schemas.safe_str.Safe_Str__Benchmark__Section             import Safe_Str__Benchmark__Section
from osbot_utils.helpers.performance.benchmark.schemas.safe_str.Safe_Str__Benchmark_Id                   import Safe_Str__Benchmark_Id
from osbot_utils.type_safe.primitives.domains.numerical.safe_float.Safe_Float__Percentage_Change         import Safe_Float__Percentage_Change

# Define collection subclass
class List__Benchmark_Ids(Type_Safe__List):
    expected_type = Safe_Str__Benchmark_Id

class Schema__Perf_Report__Category(Type_Safe):
    name         : Safe_Str__Benchmark__Section               # Category/section name
    total_ns     : Safe_UInt                                  # Aggregate timing
    pct_of_total : Safe_Float__Percentage_Change              # Percentage of total
    benchmarks   : List__Benchmark_Ids                        # Type-safe list of IDs
```

### 5.4 Schema__Perf_Report__Analysis

**Before (raw primitives):**
```python
class Schema__Perf_Report__Analysis(Type_Safe):
    bottleneck_id  : str
    bottleneck_pct : float
    key_insight    : str
    overhead_ns    : int
```

**After (type-safe):**
```python
from osbot_utils.type_safe.Type_Safe                                                                     import Type_Safe
from osbot_utils.type_safe.primitives.core.Safe_UInt                                                     import Safe_UInt
from osbot_utils.helpers.performance.benchmark.schemas.safe_str.Safe_Str__Benchmark_Id                   import Safe_Str__Benchmark_Id
from osbot_utils.helpers.performance.benchmark.schemas.safe_str.Safe_Str__Benchmark__Description         import Safe_Str__Benchmark__Description
from osbot_utils.type_safe.primitives.domains.numerical.safe_float.Safe_Float__Percentage_Change         import Safe_Float__Percentage_Change

class Schema__Perf_Report__Analysis(Type_Safe):
    bottleneck_id  : Safe_Str__Benchmark_Id                   # Validated benchmark ID
    bottleneck_pct : Safe_Float__Percentage_Change            # Can be negative (improvement)
    key_insight    : Safe_Str__Benchmark__Description         # Rich text, max 4096 chars
    overhead_ns    : Safe_UInt                                # Unsigned timing value
```

---

## Part 6: Creating Custom Safe Primitives

If you need a primitive that doesn't exist, create a subclass:

### 6.1 Custom Safe_Str

```python
import re
from osbot_utils.type_safe.primitives.core.Safe_Str import Safe_Str

class Safe_Str__Benchmark__Category(Safe_Str):
    max_length = 50
    regex      = re.compile(r'[^a-zA-Z0-9_ ]')   # Only allow alphanumeric, underscore, space
```

### 6.2 Custom Safe_UInt

```python
from osbot_utils.type_safe.primitives.core.Safe_UInt import Safe_UInt

class Safe_UInt__Nanoseconds(Safe_UInt):
    min_value = 0
    max_value = 1_000_000_000_000                # Max 1000 seconds in ns
```

### 6.3 Custom Safe_Float

```python
from osbot_utils.type_safe.primitives.core.Safe_Float import Safe_Float

class Safe_Float__Percentage_0_100(Safe_Float):
    min_value      = 0.0
    max_value      = 100.0
    decimal_places = 2
```

---

## Part 7: Complete Import Reference

```python
# ═══════════════════════════════════════════════════════════════════════════════
# Core Type_Safe
# ═══════════════════════════════════════════════════════════════════════════════
from osbot_utils.type_safe.Type_Safe import Type_Safe

# ═══════════════════════════════════════════════════════════════════════════════
# Core Primitives
# ═══════════════════════════════════════════════════════════════════════════════
from osbot_utils.type_safe.primitives.core.Safe_Str   import Safe_Str
from osbot_utils.type_safe.primitives.core.Safe_Int   import Safe_Int
from osbot_utils.type_safe.primitives.core.Safe_UInt  import Safe_UInt
from osbot_utils.type_safe.primitives.core.Safe_Float import Safe_Float

# ═══════════════════════════════════════════════════════════════════════════════
# Collections
# ═══════════════════════════════════════════════════════════════════════════════
from osbot_utils.type_safe.type_safe_core.collections.Type_Safe__Dict  import Type_Safe__Dict
from osbot_utils.type_safe.type_safe_core.collections.Type_Safe__List  import Type_Safe__List
from osbot_utils.type_safe.type_safe_core.collections.Type_Safe__Set   import Type_Safe__Set

# ═══════════════════════════════════════════════════════════════════════════════
# Identifier Primitives
# ═══════════════════════════════════════════════════════════════════════════════
from osbot_utils.type_safe.primitives.domains.identifiers.Safe_Id                    import Safe_Id
from osbot_utils.type_safe.primitives.domains.identifiers.Random_Guid                import Random_Guid
from osbot_utils.type_safe.primitives.domains.identifiers.safe_int.Timestamp_Now     import Timestamp_Now
from osbot_utils.type_safe.primitives.domains.identifiers.safe_str.Safe_Str__Id      import Safe_Str__Id

# ═══════════════════════════════════════════════════════════════════════════════
# Numerical Primitives
# ═══════════════════════════════════════════════════════════════════════════════
from osbot_utils.type_safe.primitives.domains.numerical.safe_float.Safe_Float__Percentage_Change import Safe_Float__Percentage_Change
from osbot_utils.type_safe.primitives.domains.numerical.safe_float.Safe_Float__Percentage_Exact  import Safe_Float__Percentage_Exact

# ═══════════════════════════════════════════════════════════════════════════════
# File Primitives
# ═══════════════════════════════════════════════════════════════════════════════
from osbot_utils.type_safe.primitives.domains.files.safe_str.Safe_Str__File__Path import Safe_Str__File__Path
from osbot_utils.type_safe.primitives.domains.files.safe_str.Safe_Str__File__Name import Safe_Str__File__Name

# ═══════════════════════════════════════════════════════════════════════════════
# Performance Benchmark Primitives
# ═══════════════════════════════════════════════════════════════════════════════
from osbot_utils.helpers.performance.benchmark.schemas.safe_str.Safe_Str__Benchmark_Id           import Safe_Str__Benchmark_Id
from osbot_utils.helpers.performance.benchmark.schemas.safe_str.Safe_Str__Benchmark__Section     import Safe_Str__Benchmark__Section
from osbot_utils.helpers.performance.benchmark.schemas.safe_str.Safe_Str__Benchmark__Index       import Safe_Str__Benchmark__Index
from osbot_utils.helpers.performance.benchmark.schemas.safe_str.Safe_Str__Benchmark__Title       import Safe_Str__Benchmark__Title
from osbot_utils.helpers.performance.benchmark.schemas.safe_str.Safe_Str__Benchmark__Description import Safe_Str__Benchmark__Description
from osbot_utils.helpers.performance.benchmark.schemas.safe_str.Safe_Str__Benchmark__Report      import Safe_Str__Benchmark__Report

# ═══════════════════════════════════════════════════════════════════════════════
# Performance Benchmark Enums
# ═══════════════════════════════════════════════════════════════════════════════
from osbot_utils.helpers.performance.benchmark.schemas.enums.Enum__Measure_Mode       import Enum__Measure_Mode
from osbot_utils.helpers.performance.benchmark.schemas.enums.Enum__Benchmark__Trend   import Enum__Benchmark__Trend
from osbot_utils.helpers.performance.benchmark.schemas.enums.Enum__Comparison__Status import Enum__Comparison__Status
from osbot_utils.helpers.performance.benchmark.schemas.enums.Enum__Hypothesis__Status import Enum__Hypothesis__Status
from osbot_utils.helpers.performance.benchmark.schemas.enums.Enum__Time_Unit          import Enum__Time_Unit

# ═══════════════════════════════════════════════════════════════════════════════
# Performance Benchmark Collections
# ═══════════════════════════════════════════════════════════════════════════════
from osbot_utils.helpers.performance.benchmark.schemas.collections.Dict__Benchmark_Results     import Dict__Benchmark_Results
from osbot_utils.helpers.performance.benchmark.schemas.collections.Dict__Benchmark_Sessions    import Dict__Benchmark_Sessions
from osbot_utils.helpers.performance.benchmark.schemas.collections.Dict__Benchmark__Legend     import Dict__Benchmark__Legend
from osbot_utils.helpers.performance.benchmark.schemas.collections.List__Benchmark_Sessions    import List__Benchmark_Sessions
from osbot_utils.helpers.performance.benchmark.schemas.collections.List__Benchmark_Comparisons import List__Benchmark_Comparisons
from osbot_utils.helpers.performance.benchmark.schemas.collections.List__Benchmark_Evolutions  import List__Benchmark_Evolutions
from osbot_utils.helpers.performance.benchmark.schemas.collections.List__Scores                import List__Scores
from osbot_utils.helpers.performance.benchmark.schemas.collections.List__Titles                import List__Titles
```

---

## Part 8: Quick Reference Checklist

When creating performance schemas:

- [ ] **Inherit from Type_Safe** - All schemas extend `Type_Safe`
- [ ] **Ban raw primitives** - Never use `str`, `int`, `float` directly
- [ ] **Use Safe_UInt for timing** - Nanoseconds are never negative
- [ ] **Use enums for modes** - `Enum__Measure_Mode`, not `str`
- [ ] **Use Timestamp_Now for timestamps** - Auto-generates current time
- [ ] **Create collection subclasses** - `List__Scores`, not `List[int]`
- [ ] **Name collections with prefix** - `Dict__*`, `List__*`, `Set__*`
- [ ] **No methods in schemas** - Pure data containers only
- [ ] **Use domain primitives** - `Safe_Str__Benchmark_Id`, not `Safe_Str`
- [ ] **Add inline comments** - Explain type constraints, not docstrings

---

## Part 9: Existing Schemas Reference

The performance infrastructure already defines these schemas that you can reference:

| Schema | Purpose |
|--------|---------|
| `Schema__Perf__Benchmark__Result` | Single benchmark measurement |
| `Schema__Perf__Benchmark__Session` | Full session with all results |
| `Schema__Perf__Benchmark__Comparison` | Two-session benchmark diff |
| `Schema__Perf__Benchmark__Evolution` | Multi-session tracking |
| `Schema__Perf__Comparison__Two` | Two-session comparison result |
| `Schema__Perf__Evolution` | Multi-session evolution result |
| `Schema__Perf__Statistics` | Summary statistics |
| `Schema__Perf__Hypothesis__Result` | Hypothesis test outcome |
| `Schema__Perf_Benchmark__Timing__Config` | Benchmark configuration |
| `Schema__Performance_Measure__Measurement` | Raw measurement metrics |
| `Schema__Performance_Measure__Result` | Measurement results |

These are all pure data containers following the Type_Safe patterns described in this document.
